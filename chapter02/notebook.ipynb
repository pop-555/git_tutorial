{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX0PcykOimsL"
      },
      "source": [
        "# 2. OpenAI の チャット API の基礎\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGV_BIr_imsM"
      },
      "source": [
        "## 2.3. 入出力の長さの制限や料金に影響する「トークン」\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27nwBHJhimsN"
      },
      "source": [
        "### トークン\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilDk5wjMimsN"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken==0.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMbBF_-QimsN"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "text = \"ChatGPT\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "tokens = encoding.encode(text)\n",
        "for token in tokens:\n",
        "    print(encoding.decode([token]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHu3bPfJimsN"
      },
      "source": [
        "### Tokenizer と tiktoken の紹介\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiiW4j9eimsN"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "text = \"LLMを使ってクールなものを作るのは簡単だが、プロダクションで使えるものを作るのは非常に難しい。\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "tokens = encoding.encode(text)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I6jPWnPimsO"
      },
      "source": [
        "## 2.4. Chat Completions API を試す環境の準備\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns_qIVF-imsO"
      },
      "source": [
        "### OpenAI の API キーの準備\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-QqTlNeqimsO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRc_mEfMimsO"
      },
      "source": [
        "## 2.5. Chat Completions API のハンズオン\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOfeR-dYimsO"
      },
      "source": [
        "### OpenAI のライブラリ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtYElWUbimsO"
      },
      "source": [
        "#### 【注意】既知のエラーについて\n",
        "\n",
        "openai パッケージが依存する httpx のアップデートにより、`openai==1.40.6` を使用する箇所で `TypeError: Client.__init__() got an unexpected keyword argument 'proxies'` というエラーが発生するようになりました。\n",
        "\n",
        "このエラーは、`!pip install httpx==0.27.2` のように、httpx の特定バージョンをインストールすることで回避することができます。\n",
        "\n",
        "なお、Google Colab で一度上記のエラーに遭遇したあとで `!pip install httpx==0.27.2` のようにパッケージをインストールし直した場合、以下のどちらかの操作を実施する必要があります。\n",
        "\n",
        "- Google Colab の「ランタイム」から「セッションを再起動する」を実行する\n",
        "- 「ランタイムを接続解除して削除」を実行してパッケージのインストールからやり直す\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N_j8cldLimsO",
        "outputId": "1d50ffab-0bd3-4443-abe4-cfbe83a71b6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.40.6\n",
            "  Downloading openai-1.40.6-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting httpx==0.27.2\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (4.14.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.40.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.40.6) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.40.6) (0.4.1)\n",
            "Downloading openai-1.40.6-py3-none-any.whl (361 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: httpx, openai\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.91.0\n",
            "    Uninstalling openai-1.91.0:\n",
            "      Successfully uninstalled openai-1.91.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
            "google-genai 1.21.1 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed httpx-0.27.2 openai-1.40.6\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.40.6 httpx==0.27.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWc9tvDtimsO"
      },
      "source": [
        "### Chat Completions API の呼び出し\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N_0key3cimsP",
        "outputId": "942508f2-c64e-4965-f8f4-31de627c1f5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-BngZLWFIBsd05nkYdDa6Qu3ykzffE\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"こんにちは、ジョンさん！お会いできて嬉しいです。今日はどんなことについてお話ししましょうか？\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"annotations\": []\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1751181407,\n",
            "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": \"fp_62a23a81ef\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 27,\n",
            "    \"prompt_tokens\": 25,\n",
            "    \"total_tokens\": 52,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"こんにちは！私はジョンと言います！\"},\n",
        "    ],\n",
        ")\n",
        "print(response.to_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbEjzJnTimsP"
      },
      "source": [
        "### 会話履歴を踏まえた応答を得る\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CYamfH_gimsP",
        "outputId": "d22adcb9-6c4e-41c4-8370-8c60c15fbab4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-BngZPCLC76AWejUd52n4obEtDiJPB\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"はい、ジョンさんですね！あなたのお名前を教えていただきました。ほかに何かお話ししたいことがありますか？\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"annotations\": []\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1751181411,\n",
            "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": \"fp_34a54ae93c\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 31,\n",
            "    \"prompt_tokens\": 69,\n",
            "    \"total_tokens\": 100,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"こんにちは！私はジョンと言います！\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"こんにちは、ジョンさん！お会いできて嬉しいです。今日はどんなことをお話ししましょうか？\"},\n",
        "        {\"role\": \"user\", \"content\": \"私の名前が分かりますか？\"},\n",
        "    ],\n",
        ")\n",
        "print(response.to_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz7ZRXyRimsP"
      },
      "source": [
        "### ストリーミングで応答を得る\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LSzLYiCgimsP",
        "outputId": "63f5f0fe-f1d3-44ee-940f-b55c5940f18b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "こんにちは、ジョンさん！お会いできてうれしいです。今日はどんなことをお話ししましょうか？"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"こんにちは！私はジョンと言います！\"},\n",
        "    ],\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "for chunk in response:\n",
        "    content = chunk.choices[0].delta.content\n",
        "    if content is not None:\n",
        "        print(content, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L82XUScCimsP"
      },
      "source": [
        "### JSON モード\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Qtp7hAb9imsP",
        "outputId": "5a4a6fdf-4075-4c6b-bf86-cc7c956079e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"people\": [\"おじいさん\", \"おばあさん\"]}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": '人物一覧を次のJSON形式で出力してください。\\n{\"people\": [\"aaa\", \"bbb\"]}',\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"昔々あるところにおじいさんとおばあさんがいました\",\n",
        "        },\n",
        "    ],\n",
        "    response_format={\"type\": \"json_object\"},\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSJRbTKHimsP"
      },
      "source": [
        "### Vision（画像入力）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8ydhPC5TjKhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI  # OpenAIライブラリを使うよ\n",
        "\n",
        "client = OpenAI()  # AIと話すための電話を作るよ\n",
        "\n",
        "image_url = \"https://raw.githubusercontent.com/yoshidashingo/langchain-book/main/assets/cover.jpg\"  # 説明してもらいたい画像のURLだよ\n",
        "\n",
        "response = client.chat.completions.create(  # AIに画像を送って説明してもらうよ\n",
        "    model=\"gpt-4o-mini\",  # gpt-4o は画像も見られるモデルだよ（miniは画像非対応💦）\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"画像を説明してください。\"},  # ユーザーからのお願い「この画像なに？」\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},  # 実際に見てほしい画像のURLを渡すよ\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)  # AIの返事を画面に表示するよ\n"
      ],
      "metadata": {
        "id": "rxvMw3a5jH96",
        "outputId": "3fe5902d-76cb-4a8c-e3d7-784ffbd0dbe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "この画像は書籍の表紙です。タイトルは「ChatGPT/LangChainによるチャットシステム構築【実践】入門」となっています。著者は吉田真吾さんと大場秀樹さんです。表紙には色とりどりのオウムのイラストが描かれており、デザインには青色が基調として使われています。書籍はChatGPTやLangChainに関連した内容をテーマにしているようです。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZX6NVmvimsP"
      },
      "source": [
        "### （コラム）Completions API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "B6pVMAzlimsP",
        "outputId": "8ac57d9a-6c49-406a-81ba-139c414266db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"cmpl-BngbUOnCXhBRIctmtcGOSHgMoci8N\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"length\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"\\n\\nこんにちは、ジョンさん！どんなことに興\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1751181540,\n",
            "  \"model\": \"gpt-3.5-turbo-instruct:20230824-v2\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 16,\n",
            "    \"prompt_tokens\": 11,\n",
            "    \"total_tokens\": 27\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=\"こんにちは！私はジョンと言います！\",\n",
        ")\n",
        "print(response.to_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Btssa4nimsP"
      },
      "source": [
        "## 2.6. Function calling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAhtclYPimsP"
      },
      "source": [
        "### Function calling のサンプルコード\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VgCgXp5himsP"
      },
      "outputs": [],
      "source": [
        "import json  # JSONというデータの形を使うための道具を用意するよ（辞書みたいなデータの形）\n",
        "\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):  # 場所（都市）と温度の単位を受け取る関数だよ。デフォルトは「華氏」\n",
        "    if \"tokyo\" in location.lower():  # 入力された場所が「tokyo」なら（大文字小文字は無視するよ）\n",
        "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})  # 東京の気温10を返す（unitは選べるよ）\n",
        "    elif \"san francisco\" in location.lower():  # サンフランシスコだったら\n",
        "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})  # サンフランシスコの気温を返す\n",
        "    elif \"paris\" in location.lower():  # パリだったら\n",
        "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})  # パリの気温を返す\n",
        "    else:  # 上のどれでもなかったら（知らない場所だったら）\n",
        "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})  # 気温は「わかりません」と返すよ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KKmsnx42imsQ"
      },
      "outputs": [],
      "source": [
        "tools = [  # ツール（使える関数）をまとめたリストを作るよ\n",
        "    {\n",
        "        \"type\": \"function\",  # これは「関数（function）」の種類だよって教えてる\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",  # 関数の名前だよ（AIに「この名前の関数があるよ」と伝える）\n",
        "            \"description\": \"Get the current weather in a given location\",  # 関数の説明（どんなことをする関数？）\n",
        "            \"parameters\": {  # 関数に渡すパラメータ（＝お願いに必要な情報）を教えるよ\n",
        "                \"type\": \"object\",  # 入力はオブジェクト（辞書のような形）だよ\n",
        "                \"properties\": {\n",
        "                    \"location\": {  # 「どこ？」って場所のこと\n",
        "                        \"type\": \"string\",  # 場所は文字（例：\"Tokyo\"）で書いてね\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",  # 「どんな場所？」の説明だよ\n",
        "                    },\n",
        "                    \"unit\": {  # 温度の単位だよ\n",
        "                        \"type\": \"string\",  # 単位も文字で書くよ\n",
        "                        \"enum\": [\"celsius\", \"fahrenheit\"]  # 選べるのは「摂氏」か「華氏」だけだよ\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"location\"],  # 「場所」は必ず入れてね！（unitはなくてもOK）\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0gXD8DKEimsQ",
        "outputId": "716f3ab2-5c3e-4985-bb74-901090d4a408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-BngfnkIB06jpVFCNdnUu3EpFKi2qr\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"tool_calls\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": null,\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"tool_calls\": [\n",
            "          {\n",
            "            \"id\": \"call_eRgobq09rR65AMhsoQ49rFDf\",\n",
            "            \"function\": {\n",
            "              \"arguments\": \"{\\\"location\\\":\\\"Tokyo, Japan\\\"}\",\n",
            "              \"name\": \"get_current_weather\"\n",
            "            },\n",
            "            \"type\": \"function\"\n",
            "          }\n",
            "        ],\n",
            "        \"annotations\": []\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1751181807,\n",
            "  \"model\": \"gpt-4o-2024-08-06\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": \"fp_07871e2ad8\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 17,\n",
            "    \"prompt_tokens\": 81,\n",
            "    \"total_tokens\": 98,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI  # OpenAIという会社の道具を使えるようにするよ（AIと話すための準備）\n",
        "\n",
        "client = OpenAI()  # OpenAIとつながるための電話を作っているよ（AIと会話する入口）\n",
        "\n",
        "messages = [  # AIに送るメッセージをリストで用意するよ\n",
        "    {\"role\": \"user\", \"content\": \"東京の天気はどうですか？\"},  # ユーザーが「東京の天気は？」と質問しているよ\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(  # ChatGPTに質問して返事をもらうための命令だよ\n",
        "    model=\"gpt-4o\",  # GPT-4oというかしこいAIを使うよ（画像や音声もわかる強い子！）\n",
        "    messages=messages,  # さっき用意した質問をここで使うよ\n",
        "    tools=tools,  # 天気を調べるための道具（tools）をAIに渡しているよ\n",
        ")\n",
        "\n",
        "print(response.to_json(indent=2))  # AIからの返事をきれいに見やすい形で画面に表示するよ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V_DUrGocimsQ"
      },
      "outputs": [],
      "source": [
        "response_message = response.choices[0].message  # ChatGPTの返事の中で、一番最初のメッセージを取り出してるよ\n",
        "messages.append(response_message.to_dict())  # その返事を辞書の形に変えて、次の会話に使うためリストに追加してるよ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5HE1lXKUimsQ",
        "outputId": "0bd9d2e8-41e3-4b8e-996b-6d93a3d3531b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": null}\n"
          ]
        }
      ],
      "source": [
        "available_functions = {  # どの関数が使えるかを辞書でまとめておくよ（名前と中身をセット）\n",
        "    \"get_current_weather\": get_current_weather,  # たとえば「get_current_weather」って名前でこの関数が呼び出せるよ\n",
        "}\n",
        "\n",
        "# 使いたい関数が1つとは限らないから、全部チェックするよ\n",
        "for tool_call in response_message.tool_calls:  # ChatGPTが「これ使って！」と言ってきたツール（関数）を1つずつ見るよ\n",
        "    function_name = tool_call.function.name  # 使う関数の名前を取り出すよ（たとえば \"get_current_weather\"）\n",
        "    function_to_call = available_functions[function_name]  # その名前に対応する関数を取り出すよ\n",
        "    function_args = json.loads(tool_call.function.arguments)  # ChatGPTから送られた「引数」を辞書の形に読み取るよ\n",
        "\n",
        "    function_response = function_to_call(  # 実際に関数を実行するよ\n",
        "        location=function_args.get(\"location\"),  # 「場所」の情報を渡して\n",
        "        unit=function_args.get(\"unit\"),  # 「摂氏 or 華氏」の情報も渡すよ\n",
        "    )\n",
        "    print(function_response)  # 関数の結果（たとえば天気）を画面に表示するよ\n",
        "\n",
        "    messages.append(  # 関数の実行結果を会話履歴に追加して、ChatGPTが続きを話せるようにするよ\n",
        "        {\n",
        "            \"tool_call_id\": tool_call.id,  # どのツールの返事なのかをつなげて記録するよ\n",
        "            \"role\": \"tool\",  # これはツールからの返事だよ、っていう役割の名前\n",
        "            \"name\": function_name,  # どの関数からの返事か\n",
        "            \"content\": function_response,  # 実際の返事の中身（たとえば天気情報）\n",
        "        }\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ezWLkHV5imsQ",
        "outputId": "3140ea99-1225-499d-d28b-e83bf77f9661",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"role\": \"user\",\n",
            "    \"content\": \"東京の天気はどうですか？\"\n",
            "  },\n",
            "  {\n",
            "    \"content\": null,\n",
            "    \"refusal\": null,\n",
            "    \"role\": \"assistant\",\n",
            "    \"tool_calls\": [\n",
            "      {\n",
            "        \"id\": \"call_eRgobq09rR65AMhsoQ49rFDf\",\n",
            "        \"function\": {\n",
            "          \"arguments\": \"{\\\"location\\\":\\\"Tokyo, Japan\\\"}\",\n",
            "          \"name\": \"get_current_weather\"\n",
            "        },\n",
            "        \"type\": \"function\"\n",
            "      }\n",
            "    ],\n",
            "    \"annotations\": []\n",
            "  },\n",
            "  {\n",
            "    \"tool_call_id\": \"call_eRgobq09rR65AMhsoQ49rFDf\",\n",
            "    \"role\": \"tool\",\n",
            "    \"name\": \"get_current_weather\",\n",
            "    \"content\": \"{\\\"location\\\": \\\"Tokyo\\\", \\\"temperature\\\": \\\"10\\\", \\\"unit\\\": null}\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(json.dumps(messages, ensure_ascii=False, indent=2))  # 今までの会話のやりとり（messages）を見やすい形にして画面に出すよ（日本語もそのまま見えるようにするよ）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_5ZrO2c1imsQ",
        "outputId": "dd60adea-6194-43c7-93fd-16680e248a76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-BngkV9fQdyQm398nJYxub5imy97Ce\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"東京の現在の気温は約10度です。詳細な天気情報を確認するには、天気予報のアプリやウェブサイトを参照してください。\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"annotations\": []\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1751182099,\n",
            "  \"model\": \"gpt-4o-2024-08-06\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": \"fp_07871e2ad8\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 38,\n",
            "    \"prompt_tokens\": 59,\n",
            "    \"total_tokens\": 97,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "second_response = client.chat.completions.create(  # さっきまでの会話の続きとして、もう一度ChatGPTに返事をお願いするよ\n",
        "    model=\"gpt-4o\",  # GPT-4oっていうかしこいAIを使うよ\n",
        "    messages=messages,  # 今までの会話の全部をまとめて渡して、「次どう答える？」と聞いてるよ\n",
        ")\n",
        "print(second_response.to_json(indent=2))  # ChatGPTの返事を、読みやすい形で画面に表示するよ（中身をじっくり見るため）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vQoB78limsQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}