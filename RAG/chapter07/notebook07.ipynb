{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmq_jOHq3dOo"
      },
      "source": [
        "# 7. LangSmith ã‚’ä½¿ã£ãŸ RAG ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è©•ä¾¡\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35pHjJu53dOo"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hoYDgSw3dOp"
      },
      "outputs": [],
      "source": [
        "# ã€æ³¨æ„ã€‘\n",
        "# ä¸Šè¨˜ã® `!pip install numpy==1.26.4` ã‚’å®Ÿè¡Œã—ãŸã‚ã¨ã€\n",
        "# Google Colab ä¸Šéƒ¨ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã€ã®ã€Œã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å†èµ·å‹•ã™ã‚‹ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n",
        "# ãã®å¾Œã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ `1.26.4` ã¨è¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(np.__version__)\n",
        "assert np.__version__ == \"1.26.4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:32:34.489407Z",
          "iopub.status.busy": "2024-06-28T02:32:34.488775Z",
          "iopub.status.idle": "2024-06-28T02:32:34.491583Z",
          "shell.execute_reply": "2024-06-28T02:32:34.491086Z"
        },
        "id": "ZT3qzPzP3dOp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fczNkOzH3dOp"
      },
      "source": [
        "## 7.4. Ragas ã«ã‚ˆã‚‹åˆæˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnWt2F9B3dOq"
      },
      "source": [
        "### ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rj9V_gBL3dOq"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-core==0.2.30 langchain-openai==0.1.21 \\\n",
        "    langchain-community==0.2.12 GitPython==3.1.43 \\\n",
        "    langchain-chroma==0.1.2 chromadb==0.5.3 \\\n",
        "    ragas==0.1.14 nest-asyncio==1.6.0 pydantic==2.10.6\n",
        "\n",
        "# ğŸ“¦ ã™ã¹ã¦ã®LangChainé–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã¾ã¨ã‚ã¦æœ€æ–°ã®å®‰å®šç‰ˆã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹ã‚ˆï¼\n",
        "!pip install -U langchain langchain-core langchain-openai langchain-community langsmith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOaEknhk3dOq"
      },
      "source": [
        "### æ¤œç´¢å¯¾è±¡ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ­ãƒ¼ãƒ‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtGpZwEQ3dOq"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import GitLoader  # GitHubã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–ã‚Šå‡ºã™é“å…·ã‚’ä½¿ã†ã‚ˆ\n",
        "\n",
        "def file_filter(file_path: str) -> bool:  # ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã‚’è¦‹ã¦ã€ä½¿ã†ã‹ã©ã†ã‹ã‚’æ±ºã‚ã‚‹ãƒ«ãƒ¼ãƒ«ã‚’ä½œã‚‹ã‚ˆ\n",
        "    return file_path.endswith(\".mdx\")  # ã€Œ.mdxã€ã§çµ‚ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã ã‘OKã£ã¦ãƒ«ãƒ¼ãƒ«ã ã‚ˆ\n",
        "\n",
        "loader = GitLoader(  # GitHubã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€æº–å‚™ã‚’ã™ã‚‹ã‚ˆ\n",
        "    clone_url=\"https://github.com/langchain-ai/langchain\",  # GitHubã®ãƒšãƒ¼ã‚¸ã®å ´æ‰€ï¼ˆURLï¼‰ã ã‚ˆ\n",
        "    repo_path=\"./langchain\",  # ãƒ‘ã‚½ã‚³ãƒ³ã®ä¸­ã«ä¿å­˜ã™ã‚‹ã¨ãã®ãƒ•ã‚©ãƒ«ãƒ€ã®åå‰ã ã‚ˆ\n",
        "    branch=\"master\",  # GitHubã®ä¸­ã®ã€Œmasterã€ã£ã¦ã„ã†ãƒ¡ã‚¤ãƒ³ã®ãƒšãƒ¼ã‚¸ã‚’è¦‹ã‚‹ã‚ˆ\n",
        "    file_filter=file_filter,  # ã•ã£ãã®ã€Œ.mdxã ã‘OKã€ã®ãƒ«ãƒ¼ãƒ«ã‚’ä½¿ã†ã‚ˆ\n",
        ")\n",
        "\n",
        "documents = loader.load()  # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿéš›ã«èª­ã¿è¾¼ã‚“ã§å–ã‚Šå‡ºã™ã‚ˆ\n",
        "print(len(documents))  # ä½•å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã ã‹æ•°ãˆã¦è¡¨ç¤ºã™ã‚‹ã‚ˆ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdY6hs0A3dOq"
      },
      "source": [
        "### Ragas ã«ã‚ˆã‚‹åˆæˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®å®Ÿè£…\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNaAzwtg3dOr"
      },
      "outputs": [],
      "source": [
        "for document in documents:  # ã™ã¹ã¦ã®èª­ã¿è¾¼ã‚“ã æ–‡æ›¸ã‚’é †ç•ªã«è¦‹ã‚‹ã‚ˆ\n",
        "    document.metadata[\"filename\"] = document.metadata[\"source\"]  # å…ƒã®å ´æ‰€ï¼ˆsourceï¼‰ã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã¨ã—ã¦ãƒ¡ãƒ¢ã—ã¦ãŠãã‚ˆ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKwDDagk3dOr"
      },
      "source": [
        "#### ã€æ³¨æ„ã€‘æ—¢çŸ¥ã®ã‚¨ãƒ©ãƒ¼ã«ã¤ã„ã¦\n",
        "\n",
        "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã§ gpt-4o ã‚’ä½¿ç”¨ã™ã‚‹ã¨ OpenAI API ã® Usage tier æ¬¡ç¬¬ã§ RateLimitError ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "OpenAI API ã® Usage tier ã«ã¤ã„ã¦ã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä»¥ä¸‹ã®ãƒšãƒ¼ã‚¸ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "https://platform.openai.com/docs/guides/rate-limits/usage-tiers\n",
        "\n",
        "ã“ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã€ä»¥ä¸‹ã®ã©ã¡ã‚‰ã‹ã®å¯¾å¿œã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "1. åŒã˜ Tier ã§ã‚‚ gpt-4o ã‚ˆã‚Šãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆã®é«˜ã„ gpt-4o-mini ã‚’ä½¿ç”¨ã™ã‚‹\n",
        "   - ã“ã®å ´åˆã€ç”Ÿæˆã•ã‚Œã‚‹åˆæˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å“è³ªã¯ä½ããªã‚‹ã“ã¨ãŒæƒ³å®šã•ã‚Œã¾ã™\n",
        "2. èª²é‡‘ãªã©ã«ã‚ˆã‚Š Tier ã‚’ä¸Šã’ã‚‹\n",
        "   - Tier 2 ã§ RateLimitError ãŒç™ºç”Ÿã—ãªã„ã“ã¨ã‚’ç¢ºèªæ¸ˆã¿ã§ã™ (2024 å¹´ 10 æœˆ 31 æ—¥æ™‚ç‚¹)\n",
        "\n",
        "##### 2025/3/15 è¿½è¨˜\n",
        "\n",
        "LangChain ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å¢—åŠ ã«ã‚ˆã‚Šã€gpt-4o-mini ã‚’ä½¿ç”¨ã—ã¦ã‚‚ Tier 1 ã§ã¯ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "ãã®å ´åˆã€ä¸Šéƒ¨ã®ã‚³ãƒ¼ãƒ‰ã® GitHub ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ç®‡æ‰€ã§ã€ä»¥ä¸‹ã®ã‚ˆã†ã« `langchain==0.2.13` ã¨ã„ã†å‹•ä½œç¢ºèªæ¸ˆã¿ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®šã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "```python\n",
        "loader = GitLoader(\n",
        "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
        "    repo_path=\"./langchain\",\n",
        "    branch=\"langchain==0.2.13\",\n",
        "    file_filter=file_filter,\n",
        ")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UbvzgMh3dOr"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio  # ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã€Œå¾…ã£ã¦ã­å‡¦ç†ï¼ˆéåŒæœŸï¼‰ã€ã‚’ä½¿ã„ã‚„ã™ãã™ã‚‹ãŸã‚ã®é“å…·ã ã‚ˆ\n",
        "from ragas.testset.generator import TestsetGenerator  # ãƒ†ã‚¹ãƒˆå•é¡Œã‚’ä½œã£ã¦ãã‚Œã‚‹ã‚¯ãƒ©ã‚¹ã‚’èª­ã¿è¾¼ã‚€ã‚ˆ\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context  # å•é¡Œã®ç¨®é¡ï¼ˆã‹ã‚“ãŸã‚“ãƒ»è€ƒãˆã‚‹ãƒ»ã„ãã¤ã‹ã®æƒ…å ±ã‚’ä½¿ã†ï¼‰ã‚’ä½¿ã†ã‚ˆ\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # OpenAIã®ãƒãƒ£ãƒƒãƒˆã¨æ–‡ç« ã®ç‰¹å¾´ã¥ã‘ï¼ˆåŸ‹ã‚è¾¼ã¿ï¼‰ã‚’ä½¿ã†ã‚ˆ\n",
        "\n",
        "nest_asyncio.apply()  # ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ä¸­ã§ã‚‚ã€ŒéåŒæœŸã€ãŒã†ã¾ãå‹•ãã‚ˆã†ã«ã™ã‚‹ã‚ˆï¼ˆãŠã¾ã˜ãªã„ã¿ãŸã„ãªã‚‚ã®ï¼‰\n",
        "\n",
        "generator = TestsetGenerator.from_langchain(  # ãƒ†ã‚¹ãƒˆä½œæˆãƒ­ãƒœãƒƒãƒˆã‚’ä½œã‚‹ã‚ˆï¼ˆæ–‡ç« ã‚’èª­ã‚“ã§è³ªå•ã‚’ä½œã‚‹ä¿‚ã¨ã€è©•ä¾¡ã™ã‚‹ä¿‚ã‚’å…¥ã‚Œã‚‹ã‚ˆï¼‰\n",
        "    generator_llm=ChatOpenAI(model=\"gpt-4o\"),  # è³ªå•ã‚’ä½œã‚‹ãŸã‚ã®AIã‚’æŒ‡å®šã™ã‚‹ã‚ˆï¼ˆGPT-4oï¼‰\n",
        "    critic_llm=ChatOpenAI(model=\"gpt-4o\"),  # è³ªå•ãŒã‚ˆã„ã‹ãƒã‚§ãƒƒã‚¯ã™ã‚‹AIã‚‚GPT-4oã‚’ä½¿ã†ã‚ˆ\n",
        "    embeddings=OpenAIEmbeddings(),  # æ–‡ç« ã‚’ç‰¹å¾´ã«ã™ã‚‹é“å…·ã‚’ä½¿ã†ã‚ˆ\n",
        ")\n",
        "\n",
        "testset = generator.generate_with_langchain_docs(  # æ–‡ç« ã‹ã‚‰ãƒ†ã‚¹ãƒˆå•é¡Œã‚’ä½œã‚‹ã‚ˆ\n",
        "    documents,  # å…¥åŠ›ã™ã‚‹æ–‡ç« ã®ãƒªã‚¹ãƒˆã ã‚ˆ\n",
        "    test_size=4,  # å•é¡Œã‚’4å•ä½œã‚‹ã‚ˆ\n",
        "    distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25},  # ã‹ã‚“ãŸã‚“å•é¡Œ50%ã€è€ƒãˆã‚‹å•é¡Œ25%ã€ã„ãã¤ã‹ã®æ–‡ã‚’ä½¿ã†å•é¡Œ25%ã§å‡ºé¡Œã™ã‚‹ã‚ˆ\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA5b7ITE3dOs"
      },
      "outputs": [],
      "source": [
        "testset.to_pandas()  # ä½œã£ãŸãƒ†ã‚¹ãƒˆã‚’è¡¨ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰ã«å¤‰ãˆã¦è¦‹ã‚„ã™ãã™ã‚‹ã‚ˆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YRWdxU83dOt"
      },
      "source": [
        "### LangSmith ã® Dataset ã®ä½œæˆ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB3jNgOq3dOt"
      },
      "outputs": [],
      "source": [
        "from langsmith import Client  # LangSmithã¨ã„ã†ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ã†ãŸã‚ã®é“å…·ã‚’å‘¼ã³å‡ºã™ã‚ˆ\n",
        "\n",
        "dataset_name = \"agent-book\"  # ä¿å­˜ã™ã‚‹ãƒãƒ¼ãƒˆï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰ã®åå‰ã‚’æ±ºã‚ã‚‹ã‚ˆ\n",
        "\n",
        "client = Client()  # LangSmithã¨ã‚„ã‚Šå–ã‚Šã™ã‚‹ä¿‚ã‚’ç”¨æ„ã™ã‚‹ã‚ˆ\n",
        "\n",
        "# ã‚‚ã—ã™ã§ã«åŒã˜åå‰ã®ãƒãƒ¼ãƒˆãŒã‚ã£ãŸã‚‰å‰Šé™¤ã™ã‚‹ã‚ˆï¼ˆæ–°ã—ãä½œã‚Šç›´ã™ãŸã‚ï¼‰\n",
        "if client.has_dataset(dataset_name=dataset_name):  # åŒã˜åå‰ã®ãƒãƒ¼ãƒˆãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
        "    client.delete_dataset(dataset_name=dataset_name)  # ã‚ã‚Œã°æ¶ˆã™ã‚ˆ\n",
        "\n",
        "# æ–°ã—ã„ãƒãƒ¼ãƒˆã‚’ä½œã‚‹ã‚ˆ\n",
        "dataset = c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipssUqVv3dOt"
      },
      "source": [
        "### åˆæˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylLXYZfj3dOt"
      },
      "outputs": [],
      "source": [
        "# å…¥åŠ›ï¼ˆè³ªå•ï¼‰ãƒ»å‡ºåŠ›ï¼ˆç­”ãˆï¼‰ãƒ»ãƒ¡ãƒ¢ï¼ˆã©ã“ã‹ã‚‰æ¥ãŸã‹ãªã©ï¼‰ã‚’å…¥ã‚Œã‚‹ç®±ã‚’ç”¨æ„ã™ã‚‹ã‚ˆ\n",
        "inputs = []  # è³ªå•ã ã‘ã‚’å…¥ã‚Œã‚‹ãƒªã‚¹ãƒˆ\n",
        "outputs = []  # ç­”ãˆï¼ˆæ­£è§£ã¨æ–‡è„ˆï¼‰ã‚’å…¥ã‚Œã‚‹ãƒªã‚¹ãƒˆ\n",
        "metadatas = []  # ã©ã‚“ãªé€²åŒ–ï¼ˆå•é¡Œã‚¿ã‚¤ãƒ—ï¼‰ã‹ã€ã©ã®è³‡æ–™ã‹ã‚‰æ¥ãŸã‹ã‚’å…¥ã‚Œã‚‹ãƒªã‚¹ãƒˆ\n",
        "\n",
        "# ä½œã£ãŸãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’1ã¤ãšã¤å‡¦ç†ã—ã¦ã€3ã¤ã®ãƒªã‚¹ãƒˆã«åˆ†ã‘ã¦ã„ãã‚ˆ\n",
        "for testset_record in testset.test_data:  # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’é †ç•ªã«è¦‹ã¦ã„ãã‚ˆ\n",
        "    inputs.append(  # è³ªå•ã®æƒ…å ±ã ã‘ã‚’å–ã‚Šå‡ºã—ã¦è¿½åŠ ã™ã‚‹ã‚ˆ\n",
        "        {\n",
        "            \"question\": testset_record.question,  # ãƒ†ã‚¹ãƒˆã®è³ªå•ã‚’å…¥ã‚Œã‚‹ã‚ˆ\n",
        "        }\n",
        "    )\n",
        "    outputs.append(  # ç­”ãˆã¨ãã®å…ƒã«ãªã£ãŸæ–‡ã‚’è¿½åŠ ã™ã‚‹ã‚ˆ\n",
        "        {\n",
        "            \"contexts\": testset_record.contexts,  # æ–‡è„ˆï¼ˆã©ã‚“ãªæ–‡ç« ã‚’è¦‹ã¦ç­”ãˆã‚‹ã‹ï¼‰\n",
        "            \"ground_truth\": testset_record.ground_truth,  # æ­£ã—ã„ç­”ãˆï¼ˆæ­£è§£ï¼‰ã ã‚ˆ\n",
        "        }\n",
        "    )\n",
        "    metadatas.append(  # ã©ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¥ãŸã‹ã€å•é¡Œã®ã‚¿ã‚¤ãƒ—ã¯ä½•ã‹ã‚‚å…¥ã‚Œã¦ãŠãã‚ˆ\n",
        "        {\n",
        "            \"source\": testset_record.metadata[0][\"source\"],  # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰\n",
        "            \"evolution_type\": testset_record.evolution_type,  # å•é¡Œã®ã‚¿ã‚¤ãƒ—ï¼ˆã‹ã‚“ãŸã‚“ã€è€ƒãˆã‚‹ã€ãªã©ï¼‰\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vedhhtHG3dOt"
      },
      "outputs": [],
      "source": [
        "# 3ã¤ã®ãƒªã‚¹ãƒˆã‚’LangSmithã®ãƒãƒ¼ãƒˆã«ã¾ã¨ã‚ã¦ä¿å­˜ã™ã‚‹ã‚ˆ\n",
        "client.create_examples(\n",
        "    inputs=inputs,  # è³ªå•ã®ãƒªã‚¹ãƒˆ\n",
        "    outputs=outputs,  # ç­”ãˆã®ãƒªã‚¹ãƒˆ\n",
        "    metadata=metadatas,  # ãƒ¡ãƒ¢ï¼ˆæƒ…å ±ï¼‰ã®ãƒªã‚¹ãƒˆ\n",
        "    dataset_id=dataset.id,  # ã©ã®ãƒãƒ¼ãƒˆã«æ›¸ãè¾¼ã‚€ã‹ã‚’æŒ‡å®šã™ã‚‹ã‚ˆ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzo6X6Qq3dOt"
      },
      "source": [
        "## 7.5. LangSmith ã¨ Ragas ã‚’ä½¿ã£ãŸã‚ªãƒ•ãƒ©ã‚¤ãƒ³è©•ä¾¡ã®å®Ÿè£…\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvNI32LW3dOt"
      },
      "source": [
        "### ã‚«ã‚¹ã‚¿ãƒ  Evaluator ã®å®Ÿè£…\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NCg-iGl3dOt"
      },
      "outputs": [],
      "source": [
        "from typing import Any  # ãªã‚“ã§ã‚‚å…¥ã‚‹ç®±ï¼ˆå‹ï¼‰ã‚’ä½¿ã†æº–å‚™ã ã‚ˆ\n",
        "\n",
        "# AIã®ã—ãã¿ã«å¿…è¦ãªé“å…·ãŸã¡ã‚’å‘¼ã³å‡ºã™ã‚ˆ\n",
        "from langchain_core.embeddings import Embeddings  # æ–‡ç« ã®ç‰¹å¾´ã‚’æ•°ã§è¡¨ã™é“å…·\n",
        "from langchain_core.language_models import BaseChatModel  # ãƒãƒ£ãƒƒãƒˆå‹AIã®ãƒ™ãƒ¼ã‚¹ã®é“å…·\n",
        "from langsmith.schemas import Example, Run  # LangSmithã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚„å®Ÿè¡Œã®è¨˜éŒ²ã‚’ä½¿ã†ã‚ˆ\n",
        "\n",
        "# Ragasã£ã¦ã„ã†è©•ä¾¡ãƒ„ãƒ¼ãƒ«ã®ãƒ©ãƒƒãƒ‘ãƒ¼ï¼ˆåŒ…ã‚€é“å…·ï¼‰ã‚’å‘¼ã¶ã‚ˆ\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper  # åŸ‹ã‚è¾¼ã¿ã‚’åŒ…ã‚€é“å…·\n",
        "from ragas.llms import LangchainLLMWrapper  # LLMï¼ˆAIï¼‰ã‚’åŒ…ã‚€é“å…·\n",
        "from ragas.metrics.base import Metric, MetricWithEmbeddings, MetricWithLLM  # è©•ä¾¡ã®ãƒ«ãƒ¼ãƒ«ã‚’æ±ºã‚ã‚‹é“å…·\n",
        "\n",
        "# æ¡ç‚¹ãƒã‚·ãƒ³ã‚’ä½œã‚‹ã‚¯ãƒ©ã‚¹ã ã‚ˆ\n",
        "class RagasMetricEvaluator:\n",
        "    def __init__(self, metric: Metric, llm: BaseChatModel, embeddings: Embeddings):\n",
        "        self.metric = metric  # ã©ã‚“ãªãƒ«ãƒ¼ãƒ«ã§è©•ä¾¡ã™ã‚‹ã‹ã‚’ä¿å­˜ã™ã‚‹ã‚ˆ\n",
        "\n",
        "        # AIã‚’ä½¿ã†ãƒ«ãƒ¼ãƒ«ã®å ´åˆã¯ã€AIã‚’è¨­å®šã™ã‚‹ã‚ˆ\n",
        "        if isinstance(self.metric, MetricWithLLM):  # ã‚‚ã—AIãŒå¿…è¦ãªãƒ«ãƒ¼ãƒ«ãªã‚‰\n",
        "            self.metric.llm = LangchainLLMWrapper(llm)  # AIã‚’ãƒ©ãƒƒãƒ—ã—ã¦è¨­å®šã™ã‚‹ã‚ˆ\n",
        "\n",
        "        # åŸ‹ã‚è¾¼ã¿ãŒå¿…è¦ãªãƒ«ãƒ¼ãƒ«ã®å ´åˆã¯ã€è¨­å®šã™ã‚‹ã‚ˆ\n",
        "        if isinstance(self.metric, MetricWithEmbeddings):  # ã‚‚ã—åŸ‹ã‚è¾¼ã¿ãŒå¿…è¦ãªãƒ«ãƒ¼ãƒ«ãªã‚‰\n",
        "            self.metric.embeddings = LangchainEmbeddingsWrapper(embeddings)  # åŒ…ã‚“ã§è¨­å®šã™ã‚‹ã‚ˆ\n",
        "\n",
        "    # å®Ÿè¡Œã—ãŸAIã®ç­”ãˆï¼ˆrunï¼‰ã¨æ­£è§£ã®ä¾‹ï¼ˆexampleï¼‰ã‚’ä½¿ã£ã¦ç‚¹æ•°ã‚’å‡ºã™ã‚ˆ\n",
        "    def evaluate(self, run: Run, example: Example) -> dict[str, Any]:\n",
        "        context_strs = [doc.page_content for doc in run.outputs[\"contexts\"]]  # æ–‡è„ˆã‚’æ–‡å­—ã¨ã—ã¦å–ã‚Šå‡ºã™ã‚ˆ\n",
        "\n",
        "        # Ragasã®scoreé–¢æ•°ã§ç‚¹æ•°ã‚’è¨ˆç®—ã™ã‚‹ã‚ˆ\n",
        "        score = self.metric.score({\n",
        "            \"question\": example.inputs[\"question\"],  # è³ªå•\n",
        "            \"answer\": run.outputs[\"answer\"],  # AIã®ç­”ãˆ\n",
        "            \"contexts\": context_strs,  # æ–‡è„ˆï¼ˆãƒ’ãƒ³ãƒˆï¼‰\n",
        "            \"ground_truth\": example.outputs[\"ground_truth\"],  # æœ¬å½“ã®æ­£è§£\n",
        "        })\n",
        "\n",
        "        return {\"key\": self.metric.name, \"score\": score}  # çµæœã‚’è¿”ã™ã‚ˆï¼ˆä½•ã®è©•ä¾¡ã‹ã¨ç‚¹æ•°ï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CackeOaP3dOt"
      },
      "outputs": [],
      "source": [
        "# --- è©•ä¾¡ã«ä½¿ã†AIãƒ¢ãƒ‡ãƒ«ã‚„ãƒ«ãƒ¼ãƒ«ã®è¨­å®š ---\n",
        "\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # OpenAIã®AIãƒ¢ãƒ‡ãƒ«ã‚„åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã¶ã‚ˆ\n",
        "from ragas.metrics import answer_relevancy, context_precision  # è©•ä¾¡ãƒ«ãƒ¼ãƒ«ã‚’2ã¤ä½¿ã†ã‚ˆ\n",
        "\n",
        "metrics = [context_precision, answer_relevancy]  # è©•ä¾¡ãƒ«ãƒ¼ãƒ«ã‚’ãƒªã‚¹ãƒˆã«ã¾ã¨ã‚ã‚‹ã‚ˆ\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)  # AIãƒ¢ãƒ‡ãƒ«ã‚’å†·é™ãƒ¢ãƒ¼ãƒ‰ã§ç”¨æ„ã™ã‚‹ã‚ˆ\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚‚ç”¨æ„ã™ã‚‹ã‚ˆ\n",
        "\n",
        "# å„è©•ä¾¡ãƒ«ãƒ¼ãƒ«ã«å¯¾ã—ã¦æ¡ç‚¹ãƒã‚·ãƒ³ã‚’ä½œã‚‹ã‚ˆ\n",
        "evaluators = [\n",
        "    RagasMetricEvaluator(metric, llm, embeddings).evaluate  # è©•ä¾¡ãƒã‚·ãƒ³ã‚’1ã¤ãšã¤ä½œã‚‹ã‚ˆ\n",
        "    for metric in metrics  # ãƒ«ãƒ¼ãƒ«ã®æ•°ã ã‘ç¹°ã‚Šè¿”ã™ã‚ˆ\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB5obZ0O3dOu"
      },
      "source": [
        "### æ¨è«–ã®é–¢æ•°ã®å®Ÿè£…\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGUzs-cA3dOu"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma  # Chromaã£ã¦ã„ã†æ¤œç´¢ç”¨ã®ç®±ï¼ˆãƒ™ã‚¯ãƒˆãƒ«DBï¼‰ã‚’ä½¿ã†ã‚ˆ\n",
        "from langchain_openai import OpenAIEmbeddings  # æ–‡ç« ã‚’ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰ãˆã‚‹é“å…·ï¼ˆOpenAIåŸ‹ã‚è¾¼ã¿ï¼‰ã‚’ä½¿ã†ã‚ˆ\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã§æ–‡ç« ã‚’ç‰¹å¾´ã«å¤‰ãˆã‚‹é“å…·ã‚’ä½œã‚‹ã‚ˆ\n",
        "db = Chroma.from_documents(documents, embeddings)  # èª­ã¿è¾¼ã‚“ã æ–‡æ›¸ã‚’Chromaã«å…¥ã‚Œã¦ã€æ¤œç´¢ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã‚ˆ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gxsg5XXb3dOu"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser  # AIã®è¿”äº‹ã‚’ãŸã ã®æ–‡ç« ã«æ•´ãˆã‚‹é“å…·ã‚’ä½¿ã†ã‚ˆ\n",
        "from langchain_core.prompts import ChatPromptTemplate  # AIã¸ã®è³ªå•ã®ã²ãªå½¢ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼‰ã‚’ä½œã‚‹é“å…·ã ã‚ˆ\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough  # å‡¦ç†ã‚’ã¤ãªã’ãŸã‚Šä¸¦åˆ—ã§å‹•ã‹ã™é“å…·ã ã‚ˆ\n",
        "from langchain_openai import ChatOpenAI  # OpenAIã®ãƒãƒ£ãƒƒãƒˆå‹AIã‚’ä½¿ã†ã‚ˆ\n",
        "\n",
        "# è³ªå•ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œã‚‹ã‚ˆï¼ˆæ–‡è„ˆã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã¦ã­ã€ã¨ã„ã†å†…å®¹ï¼‰\n",
        "prompt = ChatPromptTemplate.from_template('''\\\n",
        "ä»¥ä¸‹ã®æ–‡è„ˆã ã‘ã‚’è¸ã¾ãˆã¦è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "æ–‡è„ˆ: \"\"\"\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "è³ªå•: {question}\n",
        "''')\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)  # è½ã¡ç€ã„ãŸï¼ˆã¶ã‚Œãªã„ï¼‰æ€§æ ¼ã®AIã‚’ä½¿ã†ã‚ˆ\n",
        "\n",
        "retriever = db.as_retriever()  # Chromaã‚’æ¤œç´¢ãƒ­ãƒœãƒƒãƒˆã«å¤‰èº«ã•ã›ã‚‹ã‚ˆ\n",
        "\n",
        "# è³ªå•ã¨æ–‡è„ˆã‚’ä¸¦åˆ—ã§æº–å‚™ã—ã¦ã€AIã«ç­”ãˆã•ã›ã‚‹ãƒã‚§ãƒ¼ãƒ³ã‚’ä½œã‚‹ã‚ˆ\n",
        "chain = RunnableParallel(\n",
        "    {\n",
        "        \"question\": RunnablePassthrough(),  # å…¥åŠ›ã•ã‚ŒãŸè³ªå•ã‚’ãã®ã¾ã¾æ¸¡ã™ã‚ˆ\n",
        "        \"context\": retriever,  # è³ªå•ã«é–¢é€£ã™ã‚‹æ–‡æ›¸ã‚’æ¢ã™ã‚ˆ\n",
        "    }\n",
        ").assign(answer=prompt | model | StrOutputParser())  # AIã«ç­”ãˆã•ã›ã¦ã€ã‚­ãƒ¬ã‚¤ãªæ–‡ç« ã«æ•´ãˆã¦ã€Œanswerã€ã«å…¥ã‚Œã‚‹ã‚ˆ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK99e0wE3dOu"
      },
      "outputs": [],
      "source": [
        "# AIã«è³ªå•ã—ã¦ã€ç­”ãˆã¨ä½¿ã£ãŸæ–‡è„ˆã‚’è¿”ã™é–¢æ•°ã‚’ä½œã‚‹ã‚ˆ\n",
        "def predict(inputs: dict[str, Any]) -> dict[str, Any]:\n",
        "    question = inputs[\"question\"]  # å…¥ã£ã¦ããŸè³ªå•ã‚’å–ã‚Šå‡ºã™ã‚ˆ\n",
        "    output = chain.invoke(question)  # AIã«è³ªå•ã—ã¦ç­”ãˆã¦ã‚‚ã‚‰ã†ã‚ˆ\n",
        "    return {\n",
        "        \"contexts\": output[\"context\"],  # AIãŒä½¿ã£ãŸæ–‡è„ˆï¼ˆå‚è€ƒã«ã—ãŸæƒ…å ±ï¼‰ã‚’è¿”ã™ã‚ˆ\n",
        "        \"answer\": output[\"answer\"],  # AIã®ç­”ãˆã‚’è¿”ã™ã‚ˆ\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUcSMPf_3dOu"
      },
      "source": [
        "### ã‚ªãƒ•ãƒ©ã‚¤ãƒ³è©•ä¾¡ã®å®Ÿè£…ãƒ»å®Ÿè¡Œ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRm8TCxE3dOu"
      },
      "outputs": [],
      "source": [
        "from langsmith.evaluation import evaluate  # LangSmithã§ç‚¹æ•°ã‚’ã¤ã‘ã‚‹é“å…·ã‚’èª­ã¿è¾¼ã‚€ã‚ˆ\n",
        "\n",
        "# AIã®ç­”ãˆã‚’è©•ä¾¡ã—ã¦ã€ã©ã‚Œã ã‘ä¸Šæ‰‹ã«ã§ããŸã‹ã‚’ã‚¹ã‚³ã‚¢ã«ã™ã‚‹ã‚ˆ\n",
        "evaluate(\n",
        "    predict,  # ã•ã£ãä½œã£ãŸAIã¸ã®è³ªå•â†’å›ç­”ã®é–¢æ•°ã ã‚ˆ\n",
        "    data=\"agent-book\",  # è©•ä¾¡ã«ä½¿ã†ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åå‰ã ã‚ˆ\n",
        "    evaluators=evaluators,  # ã©ã‚“ãªãƒ«ãƒ¼ãƒ«ã§æ¡ç‚¹ã™ã‚‹ã‹ã‚’æ¸¡ã™ã‚ˆ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYhnWtuL3dOu"
      },
      "source": [
        "## LangSmith ã‚’ä½¿ã£ãŸã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©•ä¾¡ã®å®Ÿè£…\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDDEMo2F3dOu"
      },
      "source": [
        "### ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°ã®å®Ÿè£…\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i94lerOf3dOu"
      },
      "outputs": [],
      "source": [
        "from uuid import UUID  # ãƒ©ãƒ³ãƒ€ãƒ ãªIDï¼ˆåå‰ã®ã‹ã‚ã‚Šï¼‰ã‚’æ‰±ã†ãŸã‚ã®é“å…·ã ã‚ˆ\n",
        "\n",
        "import ipywidgets as widgets  # ãƒœã‚¿ãƒ³ã‚„UIã‚’ä½œã‚‹é“å…·ã ã‚ˆ\n",
        "from IPython.display import display  # Jupyterã§ãƒœã‚¿ãƒ³ãªã©ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®é“å…·ã ã‚ˆ\n",
        "from langsmith import Client  # LangSmithã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ã‚‹ãŸã‚ã®é“å…·ã ã‚ˆ\n",
        "\n",
        "# ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°ã‚’ã¤ãã‚‹ã‚ˆ\n",
        "def display_feedback_buttons(run_id: UUID) -> None:\n",
        "    # Goodãƒœã‚¿ãƒ³ã‚’ä½œã‚‹ã‚ˆï¼ˆç·‘ã®è¦ªæŒ‡ãƒãƒ¼ã‚¯ğŸ‘ï¼‰\n",
        "    good_button = widgets.Button(\n",
        "        description=\"Good\",  # ãƒœã‚¿ãƒ³ã«æ›¸ã‹ã‚Œã‚‹æ–‡å­—\n",
        "        button_style=\"success\",  # ç·‘è‰²ã®ãƒœã‚¿ãƒ³\n",
        "        icon=\"thumbs-up\",  # è¦ªæŒ‡ãƒãƒ¼ã‚¯\n",
        "    )\n",
        "    # Badãƒœã‚¿ãƒ³ã‚’ä½œã‚‹ã‚ˆï¼ˆèµ¤ã®è¦ªæŒ‡ä¸‹ã’ãƒãƒ¼ã‚¯ğŸ‘ï¼‰\n",
        "    bad_button = widgets.Button(\n",
        "        description=\"Bad\",  # ãƒœã‚¿ãƒ³ã«æ›¸ã‹ã‚Œã‚‹æ–‡å­—\n",
        "        button_style=\"danger\",  # èµ¤è‰²ã®ãƒœã‚¿ãƒ³\n",
        "        icon=\"thumbs-down\",  # è¦ªæŒ‡ä¸‹ã’ãƒãƒ¼ã‚¯\n",
        "    )\n",
        "\n",
        "    # ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã¨ãã®å‹•ãã‚’æ±ºã‚ã‚‹é–¢æ•°ã ã‚ˆ\n",
        "    def on_button_clicked(button: widgets.Button) -> None:\n",
        "        if button == good_button:  # GoodãŒæŠ¼ã•ã‚ŒãŸã¨ã\n",
        "            score = 1  # ç‚¹æ•°ã¯1ï¼ˆã„ã„ã­ï¼ï¼‰\n",
        "        elif button == bad_button:  # BadãŒæŠ¼ã•ã‚ŒãŸã¨ã\n",
        "            score = 0  # ç‚¹æ•°ã¯0ï¼ˆã†ãƒ¼ã‚“â€¦ï¼‰\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown button: {button}\")  # ã‚ˆãã‚ã‹ã‚‰ãªã„ãƒœã‚¿ãƒ³ãŒæ¥ãŸã‚‰ã‚¨ãƒ©ãƒ¼ã«ã™ã‚‹ã‚ˆ\n",
        "\n",
        "        client = Client()  # LangSmithã¨ã¤ãªãŒã‚‹æº–å‚™ã‚’ã™ã‚‹ã‚ˆ\n",
        "        client.create_feedback(run_id=run_id, key=\"thumbs\", score=score)  # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆGoodã‹Badï¼‰ã‚’é€ã‚‹ã‚ˆ\n",
        "        print(\"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡ã—ã¾ã—ãŸ\")  # é€ã£ãŸã‚ˆï¼ã¨è¡¨ç¤ºã™ã‚‹ã‚ˆ\n",
        "\n",
        "    # ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰ on_button_clicked ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«è¨­å®šã™ã‚‹ã‚ˆ\n",
        "    good_button.on_click(on_button_clicked)\n",
        "    bad_button.on_click(on_button_clicked)\n",
        "\n",
        "    # ç”»é¢ã«ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã™ã‚‹ã‚ˆ\n",
        "    display(good_button, bad_button)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wigH2nyG3dOu"
      },
      "source": [
        "### ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTZOxbcD3dOv"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tracers.context import collect_runs  # LangSmithã§è¨˜éŒ²ï¼ˆãƒˆãƒ¬ãƒ¼ã‚¹ï¼‰ã™ã‚‹ãŸã‚ã®é“å…·ã ã‚ˆ\n",
        "\n",
        "# AIãŒç­”ãˆãŸã¨ãã®è¨˜éŒ²ã‚’é›†ã‚ã‚‹ã‚ˆï¼ˆã©ã‚“ãªè³ªå•ã«ã©ã†ç­”ãˆãŸã‹è¨˜éŒ²ã•ã‚Œã‚‹ã‚ˆï¼‰\n",
        "with collect_runs() as runs_cb:\n",
        "    output = chain.invoke(\"LangChainã®æ¦‚è¦ã‚’æ•™ãˆã¦\")  # ã€ŒLangChainã£ã¦ä½•ï¼Ÿã€ã¨AIã«èã„ã¦ã¿ã‚‹ã‚ˆ\n",
        "    print(output[\"answer\"])  # AIã®ç­”ãˆã‚’è¡¨ç¤ºã™ã‚‹ã‚ˆ\n",
        "    run_id = runs_cb.traced_runs[0].id  # ä¸€ç•ªæœ€åˆã®è¨˜éŒ²ï¼ˆRunï¼‰ã®IDã‚’å–ã‚Šå‡ºã™ã‚ˆ\n",
        "\n",
        "# ã•ã£ãã®è¨˜éŒ²ã«å¯¾ã—ã¦ã€Good/Badãƒœã‚¿ãƒ³ã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã‚ˆ\n",
        "display_feedback_buttons(run_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tczM84Xg3dOv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}