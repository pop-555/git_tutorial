{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmq_jOHq3dOo"
      },
      "source": [
        "# 7. LangSmith を使った RAG アプリケーションの評価\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35pHjJu53dOo"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hoYDgSw3dOp"
      },
      "outputs": [],
      "source": [
        "# 【注意】\n",
        "# 上記の `!pip install numpy==1.26.4` を実行したあと、\n",
        "# Google Colab 上部のメニューから「ランタイム」の「セッションを再起動する」を実行してください。\n",
        "# その後このセルを実行して `1.26.4` と表示されることを確認してください。\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(np.__version__)\n",
        "assert np.__version__ == \"1.26.4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T02:32:34.489407Z",
          "iopub.status.busy": "2024-06-28T02:32:34.488775Z",
          "iopub.status.idle": "2024-06-28T02:32:34.491583Z",
          "shell.execute_reply": "2024-06-28T02:32:34.491086Z"
        },
        "id": "ZT3qzPzP3dOp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fczNkOzH3dOp"
      },
      "source": [
        "## 7.4. Ragas による合成テストデータの生成\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnWt2F9B3dOq"
      },
      "source": [
        "### パッケージのインストール\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rj9V_gBL3dOq"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-core==0.2.30 langchain-openai==0.1.21 \\\n",
        "    langchain-community==0.2.12 GitPython==3.1.43 \\\n",
        "    langchain-chroma==0.1.2 chromadb==0.5.3 \\\n",
        "    ragas==0.1.14 nest-asyncio==1.6.0 pydantic==2.10.6\n",
        "\n",
        "# 📦 すべてのLangChain関連ライブラリをまとめて最新の安定版にアップデートするよ！\n",
        "!pip install -U langchain langchain-core langchain-openai langchain-community langsmith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOaEknhk3dOq"
      },
      "source": [
        "### 検索対象のドキュメントのロード\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtGpZwEQ3dOq"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import GitLoader  # GitHubからファイルを取り出す道具を使うよ\n",
        "\n",
        "def file_filter(file_path: str) -> bool:  # ファイルの名前を見て、使うかどうかを決めるルールを作るよ\n",
        "    return file_path.endswith(\".mdx\")  # 「.mdx」で終わるファイルだけOKってルールだよ\n",
        "\n",
        "loader = GitLoader(  # GitHubからファイルを読み込む準備をするよ\n",
        "    clone_url=\"https://github.com/langchain-ai/langchain\",  # GitHubのページの場所（URL）だよ\n",
        "    repo_path=\"./langchain\",  # パソコンの中に保存するときのフォルダの名前だよ\n",
        "    branch=\"master\",  # GitHubの中の「master」っていうメインのページを見るよ\n",
        "    file_filter=file_filter,  # さっきの「.mdxだけOK」のルールを使うよ\n",
        ")\n",
        "\n",
        "documents = loader.load()  # ファイルを実際に読み込んで取り出すよ\n",
        "print(len(documents))  # 何個のファイルを読み込んだか数えて表示するよ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdY6hs0A3dOq"
      },
      "source": [
        "### Ragas による合成テストデータ生成の実装\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNaAzwtg3dOr"
      },
      "outputs": [],
      "source": [
        "for document in documents:  # すべての読み込んだ文書を順番に見るよ\n",
        "    document.metadata[\"filename\"] = document.metadata[\"source\"]  # 元の場所（source）をファイル名としてメモしておくよ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKwDDagk3dOr"
      },
      "source": [
        "#### 【注意】既知のエラーについて\n",
        "\n",
        "以下のコードで gpt-4o を使用すると OpenAI API の Usage tier 次第で RateLimitError が発生することが報告されています。\n",
        "\n",
        "OpenAI API の Usage tier については公式ドキュメントの以下のページを参照してください。\n",
        "\n",
        "https://platform.openai.com/docs/guides/rate-limits/usage-tiers\n",
        "\n",
        "このエラーが発生した場合は、以下のどちらかの対応を実施してください。\n",
        "\n",
        "1. 同じ Tier でも gpt-4o よりレートリミットの高い gpt-4o-mini を使用する\n",
        "   - この場合、生成される合成テストデータの品質は低くなることが想定されます\n",
        "2. 課金などにより Tier を上げる\n",
        "   - Tier 2 で RateLimitError が発生しないことを確認済みです (2024 年 10 月 31 日時点)\n",
        "\n",
        "##### 2025/3/15 追記\n",
        "\n",
        "LangChain のドキュメントの増加により、gpt-4o-mini を使用しても Tier 1 ではエラーが発生することが報告されています。\n",
        "\n",
        "その場合、上部のコードの GitHub からドキュメントをロードする箇所で、以下のように `langchain==0.2.13` という動作確認済みのバージョンを指定するようにしてください。\n",
        "\n",
        "```python\n",
        "loader = GitLoader(\n",
        "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
        "    repo_path=\"./langchain\",\n",
        "    branch=\"langchain==0.2.13\",\n",
        "    file_filter=file_filter,\n",
        ")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UbvzgMh3dOr"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio  # ノートブックで「待ってね処理（非同期）」を使いやすくするための道具だよ\n",
        "from ragas.testset.generator import TestsetGenerator  # テスト問題を作ってくれるクラスを読み込むよ\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context  # 問題の種類（かんたん・考える・いくつかの情報を使う）を使うよ\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # OpenAIのチャットと文章の特徴づけ（埋め込み）を使うよ\n",
        "\n",
        "nest_asyncio.apply()  # ノートブックの中でも「非同期」がうまく動くようにするよ（おまじないみたいなもの）\n",
        "\n",
        "generator = TestsetGenerator.from_langchain(  # テスト作成ロボットを作るよ（文章を読んで質問を作る係と、評価する係を入れるよ）\n",
        "    generator_llm=ChatOpenAI(model=\"gpt-4o\"),  # 質問を作るためのAIを指定するよ（GPT-4o）\n",
        "    critic_llm=ChatOpenAI(model=\"gpt-4o\"),  # 質問がよいかチェックするAIもGPT-4oを使うよ\n",
        "    embeddings=OpenAIEmbeddings(),  # 文章を特徴にする道具を使うよ\n",
        ")\n",
        "\n",
        "testset = generator.generate_with_langchain_docs(  # 文章からテスト問題を作るよ\n",
        "    documents,  # 入力する文章のリストだよ\n",
        "    test_size=4,  # 問題を4問作るよ\n",
        "    distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25},  # かんたん問題50%、考える問題25%、いくつかの文を使う問題25%で出題するよ\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA5b7ITE3dOs"
      },
      "outputs": [],
      "source": [
        "testset.to_pandas()  # 作ったテストを表（データフレーム）に変えて見やすくするよ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YRWdxU83dOt"
      },
      "source": [
        "### LangSmith の Dataset の作成\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB3jNgOq3dOt"
      },
      "outputs": [],
      "source": [
        "from langsmith import Client  # LangSmithというサービスを使うための道具を呼び出すよ\n",
        "\n",
        "dataset_name = \"agent-book\"  # 保存するノート（データセット）の名前を決めるよ\n",
        "\n",
        "client = Client()  # LangSmithとやり取りする係を用意するよ\n",
        "\n",
        "# もしすでに同じ名前のノートがあったら削除するよ（新しく作り直すため）\n",
        "if client.has_dataset(dataset_name=dataset_name):  # 同じ名前のノートがあるかチェック\n",
        "    client.delete_dataset(dataset_name=dataset_name)  # あれば消すよ\n",
        "\n",
        "# 新しいノートを作るよ\n",
        "dataset = c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipssUqVv3dOt"
      },
      "source": [
        "### 合成テストデータの保存\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylLXYZfj3dOt"
      },
      "outputs": [],
      "source": [
        "# 入力（質問）・出力（答え）・メモ（どこから来たかなど）を入れる箱を用意するよ\n",
        "inputs = []  # 質問だけを入れるリスト\n",
        "outputs = []  # 答え（正解と文脈）を入れるリスト\n",
        "metadatas = []  # どんな進化（問題タイプ）か、どの資料から来たかを入れるリスト\n",
        "\n",
        "# 作ったテストデータを1つずつ処理して、3つのリストに分けていくよ\n",
        "for testset_record in testset.test_data:  # テストデータを順番に見ていくよ\n",
        "    inputs.append(  # 質問の情報だけを取り出して追加するよ\n",
        "        {\n",
        "            \"question\": testset_record.question,  # テストの質問を入れるよ\n",
        "        }\n",
        "    )\n",
        "    outputs.append(  # 答えとその元になった文を追加するよ\n",
        "        {\n",
        "            \"contexts\": testset_record.contexts,  # 文脈（どんな文章を見て答えるか）\n",
        "            \"ground_truth\": testset_record.ground_truth,  # 正しい答え（正解）だよ\n",
        "        }\n",
        "    )\n",
        "    metadatas.append(  # どのファイルから来たか、問題のタイプは何かも入れておくよ\n",
        "        {\n",
        "            \"source\": testset_record.metadata[0][\"source\"],  # 元のファイルの名前\n",
        "            \"evolution_type\": testset_record.evolution_type,  # 問題のタイプ（かんたん、考える、など）\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vedhhtHG3dOt"
      },
      "outputs": [],
      "source": [
        "# 3つのリストをLangSmithのノートにまとめて保存するよ\n",
        "client.create_examples(\n",
        "    inputs=inputs,  # 質問のリスト\n",
        "    outputs=outputs,  # 答えのリスト\n",
        "    metadata=metadatas,  # メモ（情報）のリスト\n",
        "    dataset_id=dataset.id,  # どのノートに書き込むかを指定するよ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzo6X6Qq3dOt"
      },
      "source": [
        "## 7.5. LangSmith と Ragas を使ったオフライン評価の実装\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvNI32LW3dOt"
      },
      "source": [
        "### カスタム Evaluator の実装\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NCg-iGl3dOt"
      },
      "outputs": [],
      "source": [
        "from typing import Any  # なんでも入る箱（型）を使う準備だよ\n",
        "\n",
        "# AIのしくみに必要な道具たちを呼び出すよ\n",
        "from langchain_core.embeddings import Embeddings  # 文章の特徴を数で表す道具\n",
        "from langchain_core.language_models import BaseChatModel  # チャット型AIのベースの道具\n",
        "from langsmith.schemas import Example, Run  # LangSmithのテストデータや実行の記録を使うよ\n",
        "\n",
        "# Ragasっていう評価ツールのラッパー（包む道具）を呼ぶよ\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper  # 埋め込みを包む道具\n",
        "from ragas.llms import LangchainLLMWrapper  # LLM（AI）を包む道具\n",
        "from ragas.metrics.base import Metric, MetricWithEmbeddings, MetricWithLLM  # 評価のルールを決める道具\n",
        "\n",
        "# 採点マシンを作るクラスだよ\n",
        "class RagasMetricEvaluator:\n",
        "    def __init__(self, metric: Metric, llm: BaseChatModel, embeddings: Embeddings):\n",
        "        self.metric = metric  # どんなルールで評価するかを保存するよ\n",
        "\n",
        "        # AIを使うルールの場合は、AIを設定するよ\n",
        "        if isinstance(self.metric, MetricWithLLM):  # もしAIが必要なルールなら\n",
        "            self.metric.llm = LangchainLLMWrapper(llm)  # AIをラップして設定するよ\n",
        "\n",
        "        # 埋め込みが必要なルールの場合は、設定するよ\n",
        "        if isinstance(self.metric, MetricWithEmbeddings):  # もし埋め込みが必要なルールなら\n",
        "            self.metric.embeddings = LangchainEmbeddingsWrapper(embeddings)  # 包んで設定するよ\n",
        "\n",
        "    # 実行したAIの答え（run）と正解の例（example）を使って点数を出すよ\n",
        "    def evaluate(self, run: Run, example: Example) -> dict[str, Any]:\n",
        "        context_strs = [doc.page_content for doc in run.outputs[\"contexts\"]]  # 文脈を文字として取り出すよ\n",
        "\n",
        "        # Ragasのscore関数で点数を計算するよ\n",
        "        score = self.metric.score({\n",
        "            \"question\": example.inputs[\"question\"],  # 質問\n",
        "            \"answer\": run.outputs[\"answer\"],  # AIの答え\n",
        "            \"contexts\": context_strs,  # 文脈（ヒント）\n",
        "            \"ground_truth\": example.outputs[\"ground_truth\"],  # 本当の正解\n",
        "        })\n",
        "\n",
        "        return {\"key\": self.metric.name, \"score\": score}  # 結果を返すよ（何の評価かと点数）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CackeOaP3dOt"
      },
      "outputs": [],
      "source": [
        "# --- 評価に使うAIモデルやルールの設定 ---\n",
        "\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # OpenAIのAIモデルや埋め込みモデルを呼ぶよ\n",
        "from ragas.metrics import answer_relevancy, context_precision  # 評価ルールを2つ使うよ\n",
        "\n",
        "metrics = [context_precision, answer_relevancy]  # 評価ルールをリストにまとめるよ\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)  # AIモデルを冷静モードで用意するよ\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # 埋め込みモデルも用意するよ\n",
        "\n",
        "# 各評価ルールに対して採点マシンを作るよ\n",
        "evaluators = [\n",
        "    RagasMetricEvaluator(metric, llm, embeddings).evaluate  # 評価マシンを1つずつ作るよ\n",
        "    for metric in metrics  # ルールの数だけ繰り返すよ\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB5obZ0O3dOu"
      },
      "source": [
        "### 推論の関数の実装\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGUzs-cA3dOu"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma  # Chromaっていう検索用の箱（ベクトルDB）を使うよ\n",
        "from langchain_openai import OpenAIEmbeddings  # 文章を特徴ベクトルに変える道具（OpenAI埋め込み）を使うよ\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # 小さいモデルで文章を特徴に変える道具を作るよ\n",
        "db = Chroma.from_documents(documents, embeddings)  # 読み込んだ文書をChromaに入れて、検索できるようにするよ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gxsg5XXb3dOu"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser  # AIの返事をただの文章に整える道具を使うよ\n",
        "from langchain_core.prompts import ChatPromptTemplate  # AIへの質問のひな形（テンプレート）を作る道具だよ\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough  # 処理をつなげたり並列で動かす道具だよ\n",
        "from langchain_openai import ChatOpenAI  # OpenAIのチャット型AIを使うよ\n",
        "\n",
        "# 質問テンプレートを作るよ（文脈に基づいて質問に答えてね、という内容）\n",
        "prompt = ChatPromptTemplate.from_template('''\\\n",
        "以下の文脈だけを踏まえて質問に回答してください。\n",
        "\n",
        "文脈: \"\"\"\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "質問: {question}\n",
        "''')\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)  # 落ち着いた（ぶれない）性格のAIを使うよ\n",
        "\n",
        "retriever = db.as_retriever()  # Chromaを検索ロボットに変身させるよ\n",
        "\n",
        "# 質問と文脈を並列で準備して、AIに答えさせるチェーンを作るよ\n",
        "chain = RunnableParallel(\n",
        "    {\n",
        "        \"question\": RunnablePassthrough(),  # 入力された質問をそのまま渡すよ\n",
        "        \"context\": retriever,  # 質問に関連する文書を探すよ\n",
        "    }\n",
        ").assign(answer=prompt | model | StrOutputParser())  # AIに答えさせて、キレイな文章に整えて「answer」に入れるよ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK99e0wE3dOu"
      },
      "outputs": [],
      "source": [
        "# AIに質問して、答えと使った文脈を返す関数を作るよ\n",
        "def predict(inputs: dict[str, Any]) -> dict[str, Any]:\n",
        "    question = inputs[\"question\"]  # 入ってきた質問を取り出すよ\n",
        "    output = chain.invoke(question)  # AIに質問して答えてもらうよ\n",
        "    return {\n",
        "        \"contexts\": output[\"context\"],  # AIが使った文脈（参考にした情報）を返すよ\n",
        "        \"answer\": output[\"answer\"],  # AIの答えを返すよ\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUcSMPf_3dOu"
      },
      "source": [
        "### オフライン評価の実装・実行\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRm8TCxE3dOu"
      },
      "outputs": [],
      "source": [
        "from langsmith.evaluation import evaluate  # LangSmithで点数をつける道具を読み込むよ\n",
        "\n",
        "# AIの答えを評価して、どれだけ上手にできたかをスコアにするよ\n",
        "evaluate(\n",
        "    predict,  # さっき作ったAIへの質問→回答の関数だよ\n",
        "    data=\"agent-book\",  # 評価に使うテストデータセットの名前だよ\n",
        "    evaluators=evaluators,  # どんなルールで採点するかを渡すよ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYhnWtuL3dOu"
      },
      "source": [
        "## LangSmith を使ったオンライン評価の実装\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDDEMo2F3dOu"
      },
      "source": [
        "### フィードバックボタンを表示する関数の実装\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i94lerOf3dOu"
      },
      "outputs": [],
      "source": [
        "from uuid import UUID  # ランダムなID（名前のかわり）を扱うための道具だよ\n",
        "\n",
        "import ipywidgets as widgets  # ボタンやUIを作る道具だよ\n",
        "from IPython.display import display  # Jupyterでボタンなどを表示するための道具だよ\n",
        "from langsmith import Client  # LangSmithにフィードバックを送るための道具だよ\n",
        "\n",
        "# フィードバックのボタンを表示する関数をつくるよ\n",
        "def display_feedback_buttons(run_id: UUID) -> None:\n",
        "    # Goodボタンを作るよ（緑の親指マーク👍）\n",
        "    good_button = widgets.Button(\n",
        "        description=\"Good\",  # ボタンに書かれる文字\n",
        "        button_style=\"success\",  # 緑色のボタン\n",
        "        icon=\"thumbs-up\",  # 親指マーク\n",
        "    )\n",
        "    # Badボタンを作るよ（赤の親指下げマーク👎）\n",
        "    bad_button = widgets.Button(\n",
        "        description=\"Bad\",  # ボタンに書かれる文字\n",
        "        button_style=\"danger\",  # 赤色のボタン\n",
        "        icon=\"thumbs-down\",  # 親指下げマーク\n",
        "    )\n",
        "\n",
        "    # ボタンが押されたときの動きを決める関数だよ\n",
        "    def on_button_clicked(button: widgets.Button) -> None:\n",
        "        if button == good_button:  # Goodが押されたとき\n",
        "            score = 1  # 点数は1（いいね！）\n",
        "        elif button == bad_button:  # Badが押されたとき\n",
        "            score = 0  # 点数は0（うーん…）\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown button: {button}\")  # よくわからないボタンが来たらエラーにするよ\n",
        "\n",
        "        client = Client()  # LangSmithとつながる準備をするよ\n",
        "        client.create_feedback(run_id=run_id, key=\"thumbs\", score=score)  # フィードバック（GoodかBad）を送るよ\n",
        "        print(\"フィードバックを送信しました\")  # 送ったよ！と表示するよ\n",
        "\n",
        "    # ボタンが押されたら on_button_clicked を実行するように設定するよ\n",
        "    good_button.on_click(on_button_clicked)\n",
        "    bad_button.on_click(on_button_clicked)\n",
        "\n",
        "    # 画面にボタンを表示するよ\n",
        "    display(good_button, bad_button)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wigH2nyG3dOu"
      },
      "source": [
        "### フィードバックボタンを表示\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTZOxbcD3dOv"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tracers.context import collect_runs  # LangSmithで記録（トレース）するための道具だよ\n",
        "\n",
        "# AIが答えたときの記録を集めるよ（どんな質問にどう答えたか記録されるよ）\n",
        "with collect_runs() as runs_cb:\n",
        "    output = chain.invoke(\"LangChainの概要を教えて\")  # 「LangChainって何？」とAIに聞いてみるよ\n",
        "    print(output[\"answer\"])  # AIの答えを表示するよ\n",
        "    run_id = runs_cb.traced_runs[0].id  # 一番最初の記録（Run）のIDを取り出すよ\n",
        "\n",
        "# さっきの記録に対して、Good/Badボタンでフィードバックできるようにするよ\n",
        "display_feedback_buttons(run_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tczM84Xg3dOv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}