{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FN128hBzP7U"
      },
      "source": [
        "# 3. プロンプトエンジニアリング\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_tXKiS95zP7V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKZ7gcnbzP7W"
      },
      "source": [
        "#### 【注意】既知のエラーについて\n",
        "\n",
        "openai パッケージが依存する httpx のアップデートにより、`openai==1.40.6` を使用する箇所で `TypeError: Client.__init__() got an unexpected keyword argument 'proxies'` というエラーが発生するようになりました。\n",
        "\n",
        "このエラーは、`!pip install httpx==0.27.2` のように、httpx の特定バージョンをインストールすることで回避することができます。\n",
        "\n",
        "なお、Google Colab で一度上記のエラーに遭遇したあとで `!pip install httpx==0.27.2` のようにパッケージをインストールし直した場合、以下のどちらかの操作を実施する必要があります。\n",
        "\n",
        "- Google Colab の「ランタイム」から「セッションを再起動する」を実行する\n",
        "- 「ランタイムを接続解除して削除」を実行してパッケージのインストールからやり直す\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p_RaUAW-zP7W",
        "outputId": "e4202db4-cad9-48c4-dc90-11d82090d737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.40.6\n",
            "  Downloading openai-1.40.6-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting httpx==0.27.2\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (4.14.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.40.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.40.6) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.40.6) (0.4.1)\n",
            "Downloading openai-1.40.6-py3-none-any.whl (361 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: httpx, openai\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.91.0\n",
            "    Uninstalling openai-1.91.0:\n",
            "      Successfully uninstalled openai-1.91.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
            "google-genai 1.21.1 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed httpx-0.27.2 openai-1.40.6\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.40.6 httpx==0.27.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syUpTxQezP7X"
      },
      "source": [
        "## 3.2. プロンプトエンジニアリングとは\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "teiqTFTTzP7Y",
        "outputId": "ce486be5-9d5d-41a0-e2c7-91d369a239e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "プロンプトエンジニアリング（Prompt Engineering）とは、特に大規模な言語モデル（LLM）やAIシステムとの対話において、最適な応答を引き出すための入力（プロンプト）を設計・調整する技術や手法のことを指します。AIに与えるプロンプトの内容や形式を工夫することで、より正確で適切な出力を得ることが目的です。\n",
            "\n",
            "プロンプトエンジニアリングの主なポイントは以下の通りです：\n",
            "\n",
            "1. **プロンプトの設計**: より良い結果を得るためには、質問の仕方や情報の提示方法を工夫する必要があります。たとえば、具体的な指示や例を提供することが重要です。\n",
            "\n",
            "2. **実験と調整**: 異なるプロンプトを試し、出力を比較することで、最も効果的なプロンプトを見つけるプロセスが含まれます。\n",
            "\n",
            "3. **コンテキストの活用**: モデルが適切に反応できるように、必要なコンテキスト情報を含めることが重要です。\n",
            "\n",
            "4. **ユーザーの意図を反映させる**: ユーザーが求める情報や結果を明確にするため、プロンプトに対する意図を明示することが求められます。\n",
            "\n",
            "この技術は、チャットボットの開発、コンテンツ生成、データの要約、自然言語処理のタスクにおいて非常に重要な役割を果たしています。プロンプトエンジニアリングを適切に行うことで、AIの能力を最大限に引き出し、実用的かつ効果的な結果を得ることが可能になります。\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI  # OpenAIのライブラリを使うよ（ChatGPTと話す準備をする）\n",
        "\n",
        "client = OpenAI()  # ChatGPTとつながるための電話を作るよ\n",
        "\n",
        "response = client.chat.completions.create(  # ChatGPTに質問して返事をもらうための命令だよ\n",
        "    model=\"gpt-4o-mini\",  # gpt-4o-miniという軽くて速いAIを使うよ\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"プロンプトエンジニアリングとは\"},  # ユーザーからの質問「プロンプトエンジニアリングってなに？」\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)  # AIからの返事の文章だけを取り出して表示するよ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Qq7ab9cozP7Y",
        "outputId": "639bfd5b-2a4c-4d5c-fd56-2c5ba7fa4d79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "プロンプトエンジニアリングとは、AIや機械学習モデルに対して効果的に指示を与えるための技術や手法を指します。適切な質問や命令を設計し、モデルから望ましい応答を引き出すことを目的としています。主に自然言語処理の分野で活用されています。\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(  # ChatGPTに質問して返事をもらう命令だよ\n",
        "    model=\"gpt-4o-mini\",  # 軽くて速いGPT-4o-miniというAIを使うよ\n",
        "    messages=[  # ChatGPTに送るメッセージのリストだよ\n",
        "        {\"role\": \"system\", \"content\": \"質問に100文字程度で答えてください。\"},  # 最初にAIにルールを伝えるよ「100文字くらいで答えてね」\n",
        "        {\"role\": \"user\", \"content\": \"プロンプトエンジニアリングとは\"},  # ユーザーからの質問だよ「プロンプトエンジニアリングってなに？」\n",
        "    ],\n",
        ")\n",
        "print(response.choices[0].message.content)  # AIから返ってきた答えの“中身の文章”だけを画面に表示するよ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8avmmQNzP7Y"
      },
      "source": [
        "## 3.3. プロンプトの構成要素の基本\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElHfock9zP7Y"
      },
      "source": [
        "### プロンプトのテンプレート化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RGqtrjwZzP7Z",
        "outputId": "8adc95d5-817e-466c-f8b6-0ebd912ad055",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "もちろん、カレーのレシピをご紹介します。以下は基本的なカレーの作り方です。\n",
            "\n",
            "---\n",
            "\n",
            "### カレーのレシピ\n",
            "\n",
            "#### 材料（4人分）\n",
            "- 鶏肉（または牛肉、豚肉）：500g\n",
            "- 玉ねぎ：2個\n",
            "- にんじん：1本\n",
            "- じゃがいも：2個\n",
            "- カレールー：1箱（約100g）\n",
            "- サラダ油：大さじ2\n",
            "- 水：800ml\n",
            "- 塩：適量\n",
            "- 胡椒：適量\n",
            "- お好みでガーリック、しょうが：各1かけ（みじん切り）\n",
            "\n",
            "#### 作り方\n",
            "\n",
            "1. **材料の下ごしらえ**\n",
            "   - 鶏肉（または選んだ肉）を一口大に切ります。\n",
            "   - 玉ねぎは薄切り、にんじんとじゃがいもは一口大の乱切りにします。\n",
            "\n",
            "2. **炒める**\n",
            "   - 鍋にサラダ油を熱し、玉ねぎを透き通るまで炒めます。\n",
            "   - お好みでガーリックやしょうがを加え、香りが立つまでさらに炒めます。\n",
            "\n",
            "3. **肉を加える**\n",
            "   - 鶏肉を鍋に加え、表面が白くなるまで炒めます。\n",
            "\n",
            "4. **野菜を加える**\n",
            "   - にんじんとじゃがいもを加え、全体を軽く炒めます。\n",
            "\n",
            "5. **水を加える**\n",
            "   - 水を加え、強火で煮立たせます。その後、中火にしてアクを取りながら約15分煮ます。\n",
            "\n",
            "6. **カレールーを加える**\n",
            "   - カレールーを割り入れ、よくかき混ぜて溶かします。さらに中火で10〜15分煮込み、好みの濃度になるまで煮続けます。\n",
            "\n",
            "7. **味を調える**\n",
            "   - 塩と胡椒で味を整えます。必要に応じてさらに煮込みます。\n",
            "\n",
            "8. **盛り付け**\n",
            "   - ご飯と一緒に皿に盛り付け、お好みで福神漬けやらっきょうを添えて完成です。\n",
            "\n",
            "---\n",
            "\n",
            "### ポイント\n",
            "- お好みで他の野菜（ピーマン、ナスなど）やスパイスを使って自分好みにアレンジできます。\n",
            "- 水の量や煮込む時間によって濃度を調整することができます。\n",
            "\n",
            "ぜひお試しください！\n"
          ]
        }
      ],
      "source": [
        "prompt = '''\\  # ChatGPTに送るメッセージのひな型（テンプレート）を作るよ\n",
        "以下の料理のレシピを考えてください。\n",
        "\n",
        "料理名: \"\"\"\n",
        "{dish}\n",
        "\"\"\"\n",
        "'''  # {dish} のところに、あとで作りたい料理の名前を入れるよ\n",
        "\n",
        "\n",
        "def generate_recipe(dish: str) -> str:  # 「料理名」をもとにレシピを作る関数を作ってるよ\n",
        "    response = client.chat.completions.create(  # ChatGPTに質問して、レシピを作ってもらう命令だよ\n",
        "        model=\"gpt-4o-mini\",  # 軽くて速いAI（GPT-4o-mini）を使うよ\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt.format(dish=dish)},  # テンプレートの中に「料理名」を入れて質問を送ってるよ\n",
        "        ],\n",
        "    )\n",
        "    return response.choices[0].message.content  # ChatGPTが返してくれたレシピの本文だけを返してるよ\n",
        "\n",
        "\n",
        "recipe = generate_recipe(\"カレー\")  # 「カレー」という料理のレシピを作ってもらうよ\n",
        "print(recipe)  # 出てきたレシピを画面に表示するよ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jWpBl5otzP7Z",
        "outputId": "d5e7638b-5c7b-4bbc-afbd-036fc0ab31b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "カレーのレシピを考えてみましょう！ここでは、一般的なチキンカレーのレシピをご紹介します。\n",
            "\n",
            "### チキンカレーのレシピ\n",
            "\n",
            "#### 材料（4人分）\n",
            "- 鶏もも肉：400g\n",
            "- 玉ねぎ：2個\n",
            "- にんにく：2片\n",
            "- 生姜：1片\n",
            "- トマト：1個（またはトマト缶1/2缶）\n",
            "- カレールー：適量（お好みで）\n",
            "- サラダ油：大さじ2\n",
            "- 水：500ml\n",
            "- 塩：適量\n",
            "- コショウ：適量\n",
            "- お好みでスパイス（クミン、ターメリック、ガーリックパウダー、チリパウダーなど）\n",
            "- パセリ（飾り用）\n",
            "\n",
            "#### 作り方\n",
            "1. **下準備**\n",
            "   - 鶏もも肉は一口大に切り、塩とコショウで下味をつけておく。\n",
            "   - 玉ねぎ、にんにく、生姜はそれぞれみじん切りにする。\n",
            "   - トマトはざく切りにする。\n",
            "\n",
            "2. **炒める**\n",
            "   - 大きめの鍋にサラダ油を熱し、玉ねぎを中火で透明になるまで炒める。\n",
            "   - にんにくと生姜を加え、香りが立つまでさらに炒める。\n",
            "\n",
            "3. **鶏肉を加える**\n",
            "   - 鶏もも肉を加え、表面が白くなるまで炒める。\n",
            "\n",
            "4. **トマトと水を加える**\n",
            "   - トマトを加えてさっと炒めた後、水を入れ、煮立たせる。\n",
            "\n",
            "5. **煮込む**\n",
            "   - アクを取り、弱火にして15-20分ほど煮込む。\n",
            "\n",
            "6. **カレールーを加える**\n",
            "   - カレールーを入れ、よく混ぜて溶かす。お好みでスパイスを加えて調整する。\n",
            "\n",
            "7. **味を調える**\n",
            "   - 塩とコショウで味を調整し、さらに10分ほど煮込む。\n",
            "\n",
            "8. **盛り付け**\n",
            "   - ご飯と一緒に皿に盛り付け、パセリを振りかけて完成！\n",
            "\n",
            "### おすすめのサイドディッシュ\n",
            "- ナンやライス、ピクルス、サラダなどが合います。\n",
            "\n",
            "### 確認ポイント\n",
            "- お好みの辛さに合わせてカレールーやスパイスの量を調整してください。\n",
            "- 野菜（じゃがいも、にんじん、ピーマンなど）を加えることで、よりボリュームアップができます。\n",
            "\n",
            "お楽しみください！\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"\\  # レシピをお願いするための文章テンプレートを作ってるよ（今は使われてないけど）\n",
        "ユーザーが入力した料理のレシピを考えてください。\n",
        "\n",
        "料理名: '''\n",
        "{dish}\n",
        "'''\n",
        "\"\"\"  # {dish} の部分に料理名を入れる形だよ（でもこの変数は下の関数では使われてないよ）\n",
        "\n",
        "\n",
        "def generate_recipe(dish: str) -> str:  # 「料理名」を入力としてレシピを作る関数だよ\n",
        "    response = client.chat.completions.create(  # ChatGPTに質問を送って返事（レシピ）をもらうよ\n",
        "        model=\"gpt-4o-mini\",  # 軽くて速いGPT-4o-miniというAIを使うよ\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"ユーザーが入力した料理のレシピを考えてください。\"},  # AIに「ルール（役割）」を教えてるよ\n",
        "            {\"role\": \"user\", \"content\": f\"{dish}\"},  # ユーザーの入力として料理名（例：カレー）を送ってるよ\n",
        "        ],\n",
        "    )\n",
        "    return response.choices[0].message.content  # ChatGPTが返してくれたレシピの内容だけを取り出して返してるよ\n",
        "\n",
        "\n",
        "recipe = generate_recipe(\"カレー\")  # 「カレー」という料理名でレシピを考えてもらうよ\n",
        "print(recipe)  # 出てきたレシピを画面に表示するよ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOi0crdTzP7Z"
      },
      "source": [
        "### 出力形式を指定する\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3mgs9icYzP7Z",
        "outputId": "58d10269-8364-480e-b30b-38761453f0ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"材料\": [\"米\", \"カレールー\", \"鶏肉\", \"玉ねぎ\", \"じゃがいも\", \"人参\", \"水\"],\n",
            "  \"手順\": [\n",
            "    \"米を洗い、炊飯器で炊く。\",\n",
            "    \"鶏肉、玉ねぎ、じゃがいも、人参を一口大に切る。\",\n",
            "    \"鍋に油を熱し、玉ねぎを炒める。\",\n",
            "    \"玉ねぎが透明になったら鶏肉を加え、表面が白くなるまで炒める。\",\n",
            "    \"じゃがいもと人参を加え、さらに炒める。\",\n",
            "    \"水を加え、沸騰したらアクを取り、蓋をして弱火で煮る。\",\n",
            "    \"野菜が柔らかくなったら、カレールーを加え、よく溶かす。\",\n",
            "    \"中火で5分ほど煮込み、全体がなじんだら火を止める。\",\n",
            "    \"炊き上がったご飯を皿に盛り、カレーをかけて完成。\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "system_prompt = \"\"\"\\\n",
        "ユーザーが入力した料理のレシピを考えてください。\n",
        "\n",
        "出力は以下のJSON形式にしてください。\n",
        "\n",
        "```\n",
        "{\n",
        "  \"材料\": [\"材料1\", \"材料2\"],\n",
        "  \"手順\": [\"手順1\", \"手順2\"]\n",
        "}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": \"カレー\"},\n",
        "    ],\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXvflDzfzP7Z"
      },
      "source": [
        "## 3.4. プロンプトエンジニアリングの定番の手法\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFXf-mAZzP7Z"
      },
      "source": [
        "### Zero-shot プロンプティング\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "j8U_YurUzP7a",
        "outputId": "df45c28b-87e7-45ce-98b7-74e8f1bd90b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ポジティブ\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(  # ChatGPTにメッセージを送って返事をもらうよ\n",
        "    model=\"gpt-4o-mini\",  # 軽くて速いGPT-4o-miniというAIを使ってるよ\n",
        "    messages=[  # ChatGPTに送るメッセージのやりとりをここに書くよ\n",
        "        {\n",
        "            \"role\": \"system\",  # これはChatGPTに「ルール（役割）」を伝える部分だよ\n",
        "            \"content\": \"入力をポジティブ・ネガティブ・中立のどれかに分類してください。\",  # 感情を3つにわけてね！とお願いしてるよ\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",  # これはユーザーからの発言（質問や意見）だよ\n",
        "            \"content\": \"ChatGPTはとても便利だ\",  # ユーザーが「ChatGPTは便利！」と発言してるよ\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)  # ChatGPTの答え（感情分類の結果）を画面に表示するよ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp3NM6PkzP7a"
      },
      "source": [
        "### Few-shot プロンプティング\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "D2HGtAgkzP7a",
        "outputId": "4d70e22b-8392-4319-ad29-5b7c381a1439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "はい、ChatGPTは多くのユーザーにとって役立つツールです。質問に答えたり、情報を提供したり、アイデアを考える手助けをすることで、さまざまな用途に応じたサポートを提供します。他にも知りたいことがあれば、お気軽にどうぞ！\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(  # ChatGPTに質問を送って、返事をもらうよ\n",
        "    model=\"gpt-4o-mini\",  # 軽くて速いGPT-4o-miniというAIを使うよ\n",
        "    messages=[  # ChatGPTとやりとりするメッセージをリストにして渡すよ\n",
        "        {\"role\": \"system\", \"content\": \"入力がAIに関係するか回答してください。\"},  # AIに「これがAIに関係してるかどうか教えてね」とお願いしてるよ\n",
        "        {\"role\": \"user\", \"content\": \"ChatGPTはとても便利だ\"},  # ユーザーが「ChatGPTは便利」と言ってるよ（これはAIの話だよね）\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)  # ChatGPTの返事（AIに関係あるかどうか）を画面に表示するよ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TPJ-pSlHzP7a",
        "outputId": "127c9c84-e19e-48a3-b89e-6c0a06311cc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(  # ChatGPTにメッセージを送って返事をもらうよ\n",
        "    model=\"gpt-4o-mini\",  # 軽くて速いGPT-4o-miniというAIを使うよ\n",
        "    messages=[  # これまでの会話を全部渡して、続きを考えてもらうよ\n",
        "        {\"role\": \"system\", \"content\": \"入力がAIに関係するか回答してください。\"},  # 最初に「AIに関係あるか判断してね」とルールを伝えてるよ\n",
        "        {\"role\": \"user\", \"content\": \"AIの進化はすごい\"},  # 最初の質問「これはAIの話？」\n",
        "        {\"role\": \"assistant\", \"content\": \"true\"},  # ChatGPTが「うん、AIの話だよ」と答えた\n",
        "        {\"role\": \"user\", \"content\": \"今日は良い天気だ\"},  # 次の質問「これはAIの話？」\n",
        "        {\"role\": \"assistant\", \"content\": \"false\"},  # ChatGPTが「いや、これはAI関係ないね」と答えた\n",
        "        {\"role\": \"user\", \"content\": \"ChatGPTはとても便利だ\"},  # 新しい質問「これはAIの話？」\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)  # ChatGPTが考えた返事（true か false）を画面に出すよ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "072xTmqSzP7a"
      },
      "source": [
        "### （コラム）Few-shot プロンプティングのその他の形式\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ftt4xUsPzP7a",
        "outputId": "ea97e3fc-8080-4af1-89dd-6a07f1cf3ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"\\  # ChatGPTに渡す質問とヒントのセットを作ってるよ\n",
        "入力がAIに関係するか回答してください。\n",
        "\n",
        "Q: AIの進化はすごい\n",
        "A: true\n",
        "Q: 今日は良い天気だ\n",
        "A: false\n",
        "Q: ChatGPTはとても便利だ\n",
        "A:\n",
        "\"\"\"  # これは「これはAIの話？ そうじゃない？」というクイズの見本と質問のセットだよ\n",
        "\n",
        "\n",
        "response = client.completions.create(  # ChatGPTに質問を送って返事をもらうよ\n",
        "    model=\"gpt-3.5-turbo-instruct\",  # 命令文（instruct）に強いモデルを使ってるよ\n",
        "    prompt=prompt,  # さっき作ったクイズ形式のテキストをそのまま渡してるよ\n",
        ")\n",
        "\n",
        "print(response.choices[0].text)  # ChatGPTの返事（true または false）を画面に表示するよ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Lw8kIWwfzP7a",
        "outputId": "d481c970-e4b4-4153-ba9c-3e6b2b80fbff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(  # ChatGPTに質問を送って、返事をもらうよ\n",
        "    model=\"gpt-4o-mini\",  # 軽くて速いGPT-4o-miniというAIを使ってるよ\n",
        "    messages=[  # ChatGPTに渡す会話の流れをここに書いてるよ\n",
        "        {\"role\": \"system\", \"content\": \"入力がAIに関係するか回答してください。\"},  # 最初にルール「AIに関係あるかどうか教えてね！」と伝えるよ\n",
        "\n",
        "        {\"role\": \"system\", \"name\": \"example_user\", \"content\": \"AIの進化はすごい\"},  # 例としての質問①「これはAIの話？」\n",
        "        {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"true\"},  # それに対する例の答え①「AIの話だからtrue」\n",
        "\n",
        "        {\"role\": \"system\", \"name\": \"example_user\", \"content\": \"今日は良い天気だ\"},  # 例としての質問②「これはAIの話？」\n",
        "        {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"false\"},  # それに対する例の答え②「天気の話だからfalse」\n",
        "\n",
        "        {\"role\": \"user\", \"content\": \"ChatGPTはとても便利だ\"},  # 本番の質問「これはAIの話かな？」\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)  # ChatGPTが出した答え（trueかfalse）を画面に表示するよ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr_1MG5wzP7a"
      },
      "source": [
        "### Zero-shot Chain-of-Thought プロンプティング\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6k8e4ppezP7a",
        "outputId": "604868a4-665b-431b-9ea5-42f44dc8f275",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(  # ChatGPTに質問を送って、答えだけをもらう命令だよ\n",
        "    model=\"gpt-4o-mini\",  # 軽くて速いGPT-4o-miniというAIを使ってるよ\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"回答だけ一言で出力してください。\"},  # AIに「答えだけ1つ出してね」とルールを伝えてるよ\n",
        "        {\"role\": \"user\", \"content\": \"10 + 2 * 3 - 4 * 2\"},  # ユーザーが計算式を送ってるよ（AIに計算してもらう）\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)  # ChatGPTが返してきた計算結果を画面に表示するよ（余計な説明なし！）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hLGce9NjzP7a",
        "outputId": "4ed59c40-0887-46f3-a197-c04e460637de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "この計算をステップバイステップで行いましょう。\n",
            "\n",
            "1. **演算子の優先順位を確認**:\n",
            "   - まず、掛け算と割り算 (＊, ÷) を優先的に計算し、その後に足し算と引き算 (+, -) を行います。\n",
            "\n",
            "2. **計算を実行**:\n",
            "   - 最初に、2 * 3を計算します。\n",
            "     - 2 * 3 = 6\n",
            "   - 次に、4 * 2を計算します。\n",
            "     - 4 * 2 = 8\n",
            "\n",
            "3. **式を置き換える**:\n",
            "   - 計算結果を式に戻すと、次のようになります。\n",
            "     - 10 + 6 - 8\n",
            "\n",
            "4. **足し算を実行**:\n",
            "   - 10 + 6 = 16\n",
            "\n",
            "5. **引き算を実行**:\n",
            "   - 16 - 8 = 8\n",
            "\n",
            "したがって、最終的な答えは8です。\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(  # ChatGPTに質問を送って、考え方つきで返してもらう命令だよ\n",
        "    model=\"gpt-4o-mini\",  # 軽くて速いGPT-4o-miniというAIを使ってるよ\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"ステップバイステップで考えてください。\"},  # 「順番にゆっくり考えてね」とAIにお願いしてるよ\n",
        "        {\"role\": \"user\", \"content\": \"10 + 2 * 3 - 4 * 2\"},  # ユーザーが計算問題を出してるよ（優先順位があるよ！）\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)  # ChatGPTの答えと考え方をまとめて表示するよ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab-cGCVczP7b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}